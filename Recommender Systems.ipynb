{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "    By Oghosa Igbinakenzua\n",
    "    MIE 451 | Decision Support Systems\n",
    "    November 5, 2017\n",
    "    \n",
    "This project involves creating a recommender engine, evaluating it to understand its performance, and making changes to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ./ml-100k/\n",
      "  inflating: ./ml-100k/allbut.pl     \n",
      "  inflating: ./ml-100k/mku.sh        \n",
      "  inflating: ./ml-100k/README        \n",
      "  inflating: ./ml-100k/u.data        \n",
      "  inflating: ./ml-100k/u.genre       \n",
      "  inflating: ./ml-100k/u.info        \n",
      "  inflating: ./ml-100k/u.item        \n",
      "  inflating: ./ml-100k/u.occupation  \n",
      "  inflating: ./ml-100k/u.user        \n",
      "  inflating: ./ml-100k/u1.base       \n",
      "  inflating: ./ml-100k/u1.test       \n",
      "  inflating: ./ml-100k/u2.base       \n",
      "  inflating: ./ml-100k/u2.test       \n",
      "  inflating: ./ml-100k/u3.base       \n",
      "  inflating: ./ml-100k/u3.test       \n",
      "  inflating: ./ml-100k/u4.base       \n",
      "  inflating: ./ml-100k/u4.test       \n",
      "  inflating: ./ml-100k/u5.base       \n",
      "  inflating: ./ml-100k/u5.test       \n",
      "  inflating: ./ml-100k/ua.base       \n",
      "  inflating: ./ml-100k/ua.test       \n",
      "  inflating: ./ml-100k/ub.base       \n",
      "  inflating: ./ml-100k/ub.test       \n"
     ]
    }
   ],
   "source": [
    "#!unzip ml-100k.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MOVIELENS_DIR = \"ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README       u.genre      u.user       u2.test      u4.test      ua.test\r\n",
      "\u001b[31mallbut.pl\u001b[m\u001b[m    u.info       u1.base      u3.base      u5.base      ub.base\r\n",
      "\u001b[31mmku.sh\u001b[m\u001b[m       u.item       u1.test      u3.test      u5.test      ub.test\r\n",
      "u.data       u.occupation u2.base      u4.base      ua.base\r\n"
     ]
    }
   ],
   "source": [
    "!ls {MOVIELENS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(folder_path, file_name):\n",
    "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating_df = getData(MOVIELENS_DIR, 'u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = len(rating_df.userID.unique())\n",
    "num_items = len(rating_df.itemID.unique())\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
    "            num_row: int. number of users\n",
    "            num_col: int. number of items\n",
    "            \n",
    "        OUTPUT:\n",
    "            matrix: 2D numpy array. row IDs are (userID-1), columns IDs are (itemID-1),\n",
    "            and the rating for (userID,itemID,rating) is the value at this row and column.  \n",
    "            Any observed ratings are zero.\n",
    "            \n",
    "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
    "            \n",
    "        NOTE 2: data can have more columns, but your function should ignore \n",
    "              additional columns.\n",
    "              \n",
    "    \"\"\"\n",
    "    matrix = np.zeros((num_users, num_items))\n",
    "    ########### your code goes here ###########\n",
    "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
    "        matrix[userID-1, itemID-1] = rating  \n",
    "    \n",
    "    ###########         end         ###########\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ...,  0.,  0.,  0.],\n",
       "       [ 4.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 5.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  5.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPreprocessor(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseLineRecSys(object):\n",
    "    def __init__(self, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            method: string. From ['popularity','useraverage']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.method_name\n",
    "        \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'popularity': self.popularity,\n",
    "            'useraverage': self.useraverage,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def useraverage(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array. this is the same dimensions and \n",
    "                row/column IDs as train_matrix, but anywhere there is a 0 in train_matrix, \n",
    "                there should be a predicted value in predictedMatrix.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByUserAverage'  \n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        ########### your code goes here ###########\n",
    "        \n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "            # Extract the items the user already rated\n",
    "            userVector = train_matrix[user, :]\n",
    "            ratedItems = userVector[userVector.nonzero()]\n",
    "            \n",
    "            # If not empty, calculate average and set as rating for the current item\n",
    "            if ratedItems.size == 0:\n",
    "                itemAvg = 0\n",
    "            else:\n",
    "                itemAvg = ratedItems.mean()\n",
    "            predictionMatrix[user, item] = itemAvg\n",
    "            \n",
    "            # report progress every 100 users\n",
    "            if (user % 100 == 0 and item == 1):\n",
    "                print (\"calculated %d users\" % (user,))\n",
    "        \n",
    "\n",
    "        ###########         end         ###########\n",
    "        return predictionMatrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def popularity(train_matrix, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                train_matrix: 2D numpy array.\n",
    "                num_users: int. Number of Users.\n",
    "                num_items: int. Number of Items.\n",
    "            OUTPUT:\n",
    "                predictionMatrix: 2D numpy array. this is the same dimensions and \n",
    "                row/column IDs as train_matrix, but anywhere there is a 0 in train_matrix, \n",
    "                there should be a predicted value in predictedMatrix.\n",
    "                \n",
    "            NOTE: see where something very similar is done in the lab in function 'predictByPopularity'    \n",
    "        \"\"\"\n",
    "        \n",
    "        predictionMatrix = np.zeros((num_users, num_items))\n",
    "        ########### your code goes here ###########\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "    \n",
    "        # For every item calculate the number of people liked (4-5) divided by the number of people that rated\n",
    "        itemPopularity = np.zeros((num_items))\n",
    "        sumOfItemsRated = 0\n",
    "        for item in range(num_items):\n",
    "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
    "            sumOfItemsRated += numOfUsersRated\n",
    "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
    "            if numOfUsersRated == 0:\n",
    "                itemPopularity[item] = 0\n",
    "            else:\n",
    "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "                \n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            # Predict rating for every item that wasn't ranked by the user (rating == 0)\n",
    "            #if rating == 0:\n",
    "            predictionMatrix[user, item] = itemPopularity[item]\n",
    "            \n",
    "            # report progress every 100 users\n",
    "            if (user % 100 == 0 and item == 1):\n",
    "                print (\"calculated %d users\" % (user,))\n",
    "        \n",
    "                \n",
    "        ###########         end         ###########\n",
    "        return predictionMatrix    \n",
    "    \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        self.__model = self.method(train_matrix, num_users, num_items)\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "            \n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.ix[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You don not have model..\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popularity_recsys = BaseLineRecSys('popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "popularity_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71017699,  0.38931298,  0.37777778, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.71017699,  0.38931298,  0.37777778, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.71017699,  0.38931298,  0.37777778, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.71017699,  0.38931298,  0.37777778, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.71017699,  0.38931298,  0.37777778, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.71017699,  0.38931298,  0.37777778, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/oghosa/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:130: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "100000it [01:02, 1609.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>0.760684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>0.804714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  popularity\n",
       "0     196     242       3  881250949    0.760684\n",
       "1     186     302       3  891717742    0.804714\n",
       "2      22     377       1  878887116    0.076923\n",
       "3     244      51       2  880606923    0.555556\n",
       "4     166     346       1  886397596    0.611111"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popularity_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_user_rating_recsys = BaseLineRecSys('useraverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "average_user_rating_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.61029412,  3.61029412,  3.61029412, ...,  3.61029412,\n",
       "         3.61029412,  3.61029412],\n",
       "       [ 3.70967742,  3.70967742,  3.70967742, ...,  3.70967742,\n",
       "         3.70967742,  3.70967742],\n",
       "       [ 2.7962963 ,  2.7962963 ,  2.7962963 , ...,  2.7962963 ,\n",
       "         2.7962963 ,  2.7962963 ],\n",
       "       ..., \n",
       "       [ 4.04545455,  4.04545455,  4.04545455, ...,  4.04545455,\n",
       "         4.04545455,  4.04545455],\n",
       "       [ 4.26582278,  4.26582278,  4.26582278, ...,  4.26582278,\n",
       "         4.26582278,  4.26582278],\n",
       "       [ 3.41071429,  3.41071429,  3.41071429, ...,  3.41071429,\n",
       "         3.41071429,  3.41071429]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/oghosa/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:126: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "100000it [01:01, 1620.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>useraverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.413043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>3.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.651261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  useraverage\n",
       "0     196     242       3  881250949     3.615385\n",
       "1     186     302       3  891717742     3.413043\n",
       "2      22     377       1  878887116     3.351562\n",
       "3     244      51       2  880606923     3.651261\n",
       "4     166     346       1  886397596     3.550000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_rating_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimBasedRecSys(object):\n",
    "\n",
    "    def __init__(self, base, method, processor=dataPreprocessor):\n",
    "        \"\"\"\n",
    "            base: string. From ['user', 'item']. User-based Similarity or Item-based\n",
    "            method: string. From ['cosine', 'euclidean', 'somethingelse']\n",
    "            processor: function name. dataPreprocessor by default\n",
    "        \"\"\"\n",
    "        self.base = base\n",
    "        self.method_name = method\n",
    "        self.method = self._getMethod(self.method_name)\n",
    "        self.processor = processor\n",
    "        self.pred_column_name = self.base+'-'+self.method_name\n",
    "    \n",
    "    def _getMethod(self, method_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'cosine': self.cosine,\n",
    "            'euclidean': self.euclidean,\n",
    "            'somethingelse': self.somethingelse,\n",
    "        }\n",
    "        \n",
    "        return switcher[method_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine(matrix):\n",
    "        \"\"\"\n",
    "            cosine similarity\n",
    "        \"\"\"\n",
    "        similarity_matrix = 1 - pairwise_distances(matrix, metric='cosine')\n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean(matrix):\n",
    "        \"\"\"\n",
    "            euclidean similarity\n",
    "        \n",
    "        INPUT\n",
    "            matrix: same as the rating matrix generated by dataPreprocessor \n",
    "            with R rows and C columns.  Outputs an R x R similarity_matrix S \n",
    "            where each S_ij should be the euclidean similarity between row i and \n",
    "            row j of matrix.\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "\n",
    "        similarity_matrix = 1 / (1 + pairwise_distances(matrix, metric='euclidean'))\n",
    "\n",
    "    \n",
    "        ###########         end         ###########    \n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def somethingelse(matrix):\n",
    "        \"\"\"\n",
    "            manhattan? or super-natural intuition similarity\n",
    "            \n",
    "        INPUT\n",
    "            matrix: same as the rating matrix generated by dataPreprocessor \n",
    "            with R rows and C columns.  Outputs an R x R similarity_matrix S \n",
    "            where each S_ij should be the somethingelse similarity between row i and \n",
    "            row j of matrix.\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "    \n",
    "    \n",
    "        similarity_matrix = 1 / (1 + pairwise_distances(matrix, metric='manhattan'))\n",
    "\n",
    "        ###########         end         ###########        \n",
    "        return similarity_matrix\n",
    "        \n",
    "    def predict_all(self, train_df, num_users, num_items):\n",
    "        \"\"\"\n",
    "            INPUT: \n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "                num_row: scalar. number of users\n",
    "                num_col: scalar. number of items\n",
    "            OUTPUT:\n",
    "                no return... this method assigns the result to self.__model\n",
    "                \n",
    "                self.__model: this is the same dimensions and row/column IDs as train_matrix, \n",
    "                but anywhere there is a 0 in train_matrix, there should be a predicted value \n",
    "                in self.__model.\n",
    "            \n",
    "            NOTES:\n",
    "                self.__model should contain predictions for *all* user and items\n",
    "                (don't worry about predicting for observed (user,item) pairs,\n",
    "                 since we won't be using these predictions in the evaluation)\n",
    "                (see 'vectorizedUserSimRecSys' code in for an efficient vectorized example)\n",
    "                \n",
    "        \"\"\"\n",
    "        train_matrix = self.processor(train_df, num_users, num_items)\n",
    "        \n",
    "        \n",
    "        temp_matrix = np.zeros(train_matrix.shape)\n",
    "        temp_matrix[train_matrix.nonzero()] = 1\n",
    "        if self.base == 'user':\n",
    "            ########### your code goes here ###########\n",
    "\n",
    "            uu_similarity = self.method(train_matrix)\n",
    "            normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            self.__model = np.matmul(uu_similarity, train_matrix)/normalizer\n",
    "            \n",
    "            # average each user's score over all the movies\n",
    "            useraverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1) + 1e-5)\n",
    "            # sum each movies over all the users \n",
    "            columns = np.sum(self.__model, axis=0)\n",
    "            # if a movie didn't get any rankings/scores add \n",
    "            self.__model[:, columns==0] = self.__model[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "          \n",
    "  \n",
    "            \n",
    "            \n",
    "            ###########         end         ###########\n",
    "            \n",
    "        elif self.base == 'item':\n",
    "            ########### your code goes here ###########\n",
    "\n",
    "            ii_similarity = self.method(np.transpose(train_matrix))\n",
    "            normalizer = np.matmul(temp_matrix, ii_similarity)\n",
    "            normalizer[normalizer == 0] = 1e-5\n",
    "            self.__model = np.matmul(train_matrix, ii_similarity)/normalizer\n",
    "            \n",
    "            itemaverage = np.sum(train_matrix, axis=1)/(np.sum(temp_matrix, axis=1) + 1e-5)\n",
    "            columns = np.sum(self.__model, axis=0)\n",
    "            self.__model[:, columns==0] = self.__model[:, columns==0] + np.expand_dims(itemaverage, axis=1)\n",
    "            \n",
    "           \n",
    "            \n",
    "            \n",
    "            ###########         end         ###########\n",
    "        else:\n",
    "            print('No other option available')\n",
    "        \n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "                              \n",
    "            NOTE: 1. data can have more columns, but your function should ignore \n",
    "                  additional columns.\n",
    "                  2. 'base-method' depends on your 'base' and 'method'. For example,\n",
    "                  if base == 'user' and method == 'cosine', \n",
    "                  then base-method == 'user-cosine'\n",
    "                  3. your predictions go to 'base-method' column\n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = test_df.copy()\n",
    "        else:\n",
    "            prediction = test_df\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            prediction.ix[index, self.pred_column_name] = self.__model[userID-1, itemID-1]\n",
    "    \n",
    "        return prediction\n",
    "    \n",
    "    def getModel(self):\n",
    "        \"\"\"\n",
    "            return predicted user-item matrix\n",
    "        \"\"\"\n",
    "        return self.__model\n",
    "    \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = None\n",
    "        except:\n",
    "            print(\"You do not have model..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of how to call similarity functions.\n",
    "I = np.eye(3)\n",
    "SimBasedRecSys.cosine(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.41421356,  0.41421356],\n",
       "       [ 0.41421356,  1.        ,  0.41421356],\n",
       "       [ 0.41421356,  0.41421356,  1.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.euclidean(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.33333333,  0.33333333],\n",
       "       [ 0.33333333,  1.        ,  0.33333333],\n",
       "       [ 0.33333333,  0.33333333,  1.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimBasedRecSys.somethingelse(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine metrics works better beacause it uses the direction (angle) beteween the vectors to measure the similarity rather than the distance between the points which could be strongly biased based on the magnitude of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I used the 'Manhattan' metric beacause since it is an absolute value distance, it should give more robust results, whereas Euclidean would be influenced by unusual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys = SimBasedRecSys('user','cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_cosine_recsys.predict_all(rating_df, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.89911175,  3.19022667,  3.0261129 , ...,  2.        ,\n",
       "         3.        ,  3.        ],\n",
       "       [ 3.84034456,  3.17139889,  2.92626717, ...,  2.        ,\n",
       "         3.        ,  3.        ],\n",
       "       [ 3.87104065,  3.12823798,  3.03250708, ...,  2.        ,\n",
       "         3.        ,  3.        ],\n",
       "       ..., \n",
       "       [ 3.90754645,  3.20227238,  3.05776201, ...,  2.        ,\n",
       "         3.        ,  3.        ],\n",
       "       [ 3.91100649,  3.21591021,  2.98854017, ...,  2.        ,\n",
       "         3.        ,  3.        ],\n",
       "       [ 3.91593122,  3.24268207,  3.08255897, ...,  0.        ,\n",
       "         3.        ,  3.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/oghosa/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:163: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "100000it [01:05, 1517.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>4.025213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>4.142828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>1.922080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.431884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.424963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  user-cosine\n",
       "0     196     242       3  881250949     4.025213\n",
       "1     186     302       3  891717742     4.142828\n",
       "2      22     377       1  878887116     1.922080\n",
       "3     244      51       2  880606923     3.431884\n",
       "4     166     346       1  886397596     3.424963"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.75429099,  3.66419957,  3.73222997, ...,  3.60248287,\n",
       "         3.79662696,  3.90232044],\n",
       "       [ 3.83658867,  3.80424519,  3.77473905, ...,  3.72798332,\n",
       "         3.9109779 ,  3.79775927],\n",
       "       [ 2.84492718,  2.89389328,  2.84327324, ...,  2.99504451,\n",
       "         3.16444153,  2.9858119 ],\n",
       "       ..., \n",
       "       [ 4.11427954,  4.0558267 ,  4.00963139, ...,  4.        ,\n",
       "         3.87872799,  4.14814803],\n",
       "       [ 4.37096823,  4.39679254,  4.33543016, ...,  3.955358  ,\n",
       "         4.41891089,  4.57995134],\n",
       "       [ 3.52030345,  3.46948821,  3.52393064, ...,  0.        ,\n",
       "         3.6110641 ,  3.59656861]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys = SimBasedRecSys('item','cosine')\n",
    "item_cosine_recsys.predict_all(rating_df, num_users, num_items)\n",
    "item_cosine_recsys.getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/oghosa/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:163: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "100000it [01:04, 1543.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item-cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>3.591314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>3.344077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>2.965365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>3.637332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>3.333013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating  timestamp  item-cosine\n",
       "0     196     242       3  881250949     3.591314\n",
       "1     186     302       3  891717742     3.344077\n",
       "2      22     377       1  878887116     2.965365\n",
       "3     244      51       2  880606923     3.637332\n",
       "4     166     346       1  886397596     3.333013"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cosine_recsys.evaluate_test(rating_df,copy=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossValidation(object):\n",
    "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(MOVIELENS_DIR)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = len([item for item in topK if item in userTestVector])/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return sumPrecisions/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = len([item for item in topK if item in userTestVector])/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return sumRecalls/countRecalls\n",
    "    \n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "            scores[algorithm.getPredColName()] = fold_scores\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to use CrossValidation Class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. gather your algorithms in previous steps.\n",
    "algorithm_instances = [item_cosine_recsys, \n",
    "                       user_cosine_recsys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Instantiate a CrossValidation instance and assign the measurement that you want to use\n",
    "# RMSE, P@K, R@K\n",
    "# Precision at K in this example\n",
    "cv_patk = CrossValidation('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/oghosa/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:163: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "20000it [00:09, 2093.38it/s]\n",
      "20000it [00:09, 2103.24it/s]\n",
      "20000it [00:09, 2079.48it/s]\n",
      "20000it [00:09, 2072.87it/s]\n",
      "20000it [00:09, 2164.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2120.12it/s]\n",
      "20000it [00:09, 2116.03it/s]\n",
      "20000it [00:09, 2129.38it/s]\n",
      "20000it [00:09, 2162.10it/s]\n",
      "20000it [00:09, 2194.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# 3. Run CV by giving:\n",
    "#    1> algorithms just gathered\n",
    "#    2> number of users in the full dataset\n",
    "#    3> number of items in the full dataset\n",
    "#    4> precision or recall at K need a K value, so k=5 means precision at 5 in this example\n",
    "results = cv_patk.run(algorithm_instances, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item-cosine': [1.033430706071607,\n",
       "  1.0169957594395471,\n",
       "  1.0045122528110584,\n",
       "  1.0099161640556313,\n",
       "  1.011190718546166],\n",
       " 'user-cosine': [1.0264490128856898,\n",
       "  1.0214387664092763,\n",
       "  1.0132940323507253,\n",
       "  1.009400399702741,\n",
       "  1.0161883960008826]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cosine\n",
      "mean:  1.01735412147\n",
      "confidence interval:  0.005414541145\n",
      "range: ( 1.01193958032 ,  1.02276866261 )\n",
      "\n",
      "item-cosine\n",
      "mean:  1.01520912018\n",
      "confidence interval:  0.00895556216199\n",
      "range: ( 1.00625355802 ,  1.02416468235 )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confidence Interval Function\n",
    "import scipy.stats as stats\n",
    "from math import sqrt\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    mu,sd = np.mean(a),np.std(a)\n",
    "    z = stats.t.ppf(confidence, n)\n",
    "    h=z*sd/sqrt(n)\n",
    "    return mu, h\n",
    "\n",
    "#print results\n",
    "for algorithim in results:\n",
    "    mu, h = mean_confidence_interval(results[algorithim], confidence=0.95)\n",
    "    print(algorithim)\n",
    "    print('mean: ', mu)\n",
    "    print('confidence interval: ', h)\n",
    "    print('range: (', (mu-h), ', ', (mu+h), ')\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The item-item cosine performed better (lower RMSE mean and lower range). A reason for this is because the item-item matix has more item ratings vs user ratings (i.e less sparse) in comparison to the user-user matrix.\n",
    "\n",
    "It is worth noting that since the 95% CIs overlap the diferences are not statiscaly significant. Running more test is a better way significatly identify a better option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/oghosa/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:126: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "20000it [00:09, 2089.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [00:00, 1815.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2184.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217it [00:00, 2168.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2123.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2239.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "214it [00:00, 2130.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2253.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2153.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2261.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2259.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2181.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2166.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2245.12it/s]\n",
      "20000it [00:08, 2248.84it/s]\n",
      "20000it [00:09, 2156.73it/s]\n",
      "20000it [00:09, 2094.83it/s]\n",
      "20000it [00:09, 2136.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2107.72it/s]\n",
      "20000it [00:09, 2222.10it/s]\n",
      "20000it [00:08, 2263.64it/s]\n",
      "20000it [00:09, 2171.56it/s]\n",
      "20000it [00:09, 2099.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "214it [00:00, 2128.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2165.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [00:00, 2109.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2125.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [00:00, 2312.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:10, 1993.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "198it [00:00, 1969.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:10, 1991.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [00:00, 1931.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:10, 1974.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2039.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:10, 1972.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2217.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2296.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2284.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2262.31it/s]\n",
      "20000it [00:09, 2166.65it/s]\n",
      "20000it [00:09, 2178.28it/s]\n",
      "20000it [00:08, 2250.55it/s]\n",
      "20000it [00:08, 2260.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2286.63it/s]\n",
      "20000it [00:08, 2301.95it/s]\n",
      "20000it [00:08, 2290.97it/s]\n",
      "20000it [00:08, 2255.36it/s]\n",
      "20000it [00:08, 2261.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm popularity\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2286.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2284.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2301.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2272.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2292.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm useraverage\n",
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2189.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2186.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2105.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2224.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:08, 2233.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm user-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2216.57it/s]\n",
      "20000it [00:09, 2218.91it/s]\n",
      "20000it [00:08, 2232.10it/s]\n",
      "20000it [00:08, 2244.25it/s]\n",
      "20000it [00:09, 2199.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm item-cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:09, 2195.37it/s]\n",
      "20000it [00:09, 2214.48it/s]\n",
      "20000it [00:09, 2204.03it/s]\n",
      "20000it [00:09, 2218.15it/s]\n",
      "20000it [00:08, 2229.19it/s]\n"
     ]
    }
   ],
   "source": [
    "algorithm_instances_Q4 = [popularity_recsys, \n",
    "                       average_user_rating_recsys, \n",
    "                       user_cosine_recsys,\n",
    "                       item_cosine_recsys]\n",
    "\n",
    "cv_rmse = CrossValidation('RMSE')\n",
    "results_rmse = cv_rmse.run(algorithm_instances_Q4, num_users, num_items,k=5)\n",
    "\n",
    "cv_pk = CrossValidation('P@K')\n",
    "results_pk = cv_pk.run(algorithm_instances_Q4, num_users, num_items,k=5)\n",
    "\n",
    "cv_rk = CrossValidation('R@K')\n",
    "results_rk = cv_rk.run(algorithm_instances_Q4, num_users, num_items,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame(columns=['algorithm', 'RMSE Avg', 'RMSE CI', 'P@K Avg', 'P@K CI', 'R@K Avg', 'R@K CI'])\n",
    "\n",
    "for algorithm in results_rmse:\n",
    "    mu_rmse, h_rmse = mean_confidence_interval(results_rmse[algorithm], confidence=0.95)\n",
    "    mu_pk, h_pk = mean_confidence_interval(results_pk[algorithm], confidence=0.95)\n",
    "    mu_rk, h_rk = mean_confidence_interval(results_rk[algorithm], confidence=0.95)\n",
    "    performance_df = performance_df.append({'algorithm':algorithm, 'RMSE Avg':mu_rmse, 'RMSE CI':h_rmse, 'P@K Avg':mu_pk, 'P@K CI':h_pk, 'R@K Avg':mu_rk, 'R@K CI':h_rk}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>RMSE Avg</th>\n",
       "      <th>RMSE CI</th>\n",
       "      <th>P@K Avg</th>\n",
       "      <th>P@K CI</th>\n",
       "      <th>R@K Avg</th>\n",
       "      <th>R@K CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>popularity</td>\n",
       "      <td>3.159093</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.550583</td>\n",
       "      <td>0.094218</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>0.075910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>useraverage</td>\n",
       "      <td>1.043718</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.473637</td>\n",
       "      <td>0.085452</td>\n",
       "      <td>0.441323</td>\n",
       "      <td>0.072713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user-cosine</td>\n",
       "      <td>1.017354</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.555843</td>\n",
       "      <td>0.094934</td>\n",
       "      <td>0.486269</td>\n",
       "      <td>0.075834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>item-cosine</td>\n",
       "      <td>1.015209</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.532216</td>\n",
       "      <td>0.096408</td>\n",
       "      <td>0.474971</td>\n",
       "      <td>0.078805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     algorithm  RMSE Avg   RMSE CI   P@K Avg    P@K CI   R@K Avg    R@K CI\n",
       "0   popularity  3.159093  0.012853  0.550583  0.094218  0.484076  0.075910\n",
       "1  useraverage  1.043718  0.009599  0.473637  0.085452  0.441323  0.072713\n",
       "2  user-cosine  1.017354  0.005415  0.555843  0.094934  0.486269  0.075834\n",
       "3  item-cosine  1.015209  0.008956  0.532216  0.096408  0.474971  0.078805"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Baseline: **Popularity**; Metric: **RMSE**: \n",
    "\n",
    "Since the popularity metric returns results on a 0-1 scale (i.e. 1 if movive is well-liked and 0 otherwise) the RMSE metric does not provide a fair comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric | Best Algorithm | Explantion\n",
    "------|---------------|-----------\n",
    "RMSE | Item Cosine | Due to the relatively large amount of item ratings, the accuarys is expected to be highter beacause more feture can be considered.\n",
    "P@K | User Cosine | This performs best because the cosine metric does not use only magnitude and because data from other users are used to personalize the results\n",
    "R@K | User Cosine | This performs best because the cosine metric does not use only magnitude and because data from other users are used to personalize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes (exlculding the popularity algorithm due to the RMSE point raised in 4b).\n",
    "\n",
    "Based on the data, the ranking metrics appear negatively correlated to the RMSE; i.e higher ranking -> lower RMSE. This is reasonable as a higer ranking should imply a lower error from acurratly predicting the user's like/dislike of a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def item_item_similarity(train_df, num_users, num_items):\n",
    "    \n",
    "    train_matrix = dataPreprocessor(train_df, num_users, num_items)\n",
    "    temp_matrix = np.zeros(train_matrix.shape)\n",
    "    temp_matrix[train_matrix.nonzero()] = 1\n",
    "\n",
    "    similarity_matrix = 1 - pairwise_distances(np.transpose(train_matrix), metric='cosine')\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fieldsMovies = ['movieID', 'movieTitle', 'releaseDate', 'videoReleaseDate', 'IMDbURL', 'unknown', 'action', 'adventure',\n",
    "          'animation', 'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'filmNoir', 'horror',\n",
    "          'musical', 'mystery', 'romance','sciFi', 'thriller', 'war', 'western']\n",
    "moviesDF = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=fieldsMovies, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682 Scream of Stone (Schrei aus Stein) (1991)\n",
      "1432 Mighty, The (1998)\n",
      "1430 Ill Gotten Gains (1997)\n",
      "1424 I Like It Like That (1994)\n",
      "1423 Walking Dead, The (1995)\n",
      "1422 Suture (1993)\n",
      "1420 Gilligan's Island: The Movie (1998)\n",
      "1417 Turning, The (1992)\n",
      "1416 No Escape (1994)\n",
      "957 Pushing Hands (1992)\n",
      "1414 Coldblooded (1995)\n",
      "1412 Land Before Time III: The Time of the Great Giving (1995) (V)\n",
      "973 Grateful Dead (1995)\n",
      "1409 Swan Princess, The (1994)\n",
      "1408 Gordy (1995)\n",
      "1407 Specialist, The (1994)\n",
      "424 Children of the Corn: The Gathering (1996)\n",
      "981 Dangerous Ground (1997)\n",
      "1371 Machine, The (1994)\n",
      "1373 Good Morning (1971)\n",
      "1374 Falling in Love Again (1980)\n",
      "1378 Rhyme & Reason (1997)\n",
      "1029 Jury Duty (1995)\n",
      "1382 Bonheur, Le (1965)\n",
      "1433 Men of Means (1998)\n",
      "1383 Second Jungle Book: Mowgli & Baloo, The (1997)\n",
      "987 Underworld (1997)\n",
      "1387 Fall (1997)\n",
      "1389 Mondo (1996)\n",
      "1390 Innocent Sleep, The (1995)\n",
      "1393 Stag (1997)\n",
      "1395 Hurricane Streets (1998)\n",
      "1384 Squeeze (1996)\n",
      "1370 I Can't Sleep (J'ai pas sommeil) (1994)\n",
      "437 Amityville 1992: It's About Time (1992)\n",
      "1437 House Party 3 (1994)\n",
      "1493 Modern Affair, A (1995)\n",
      "1259 Pie in the Sky (1995)\n",
      "893 For Richer or Poorer (1997)\n",
      "453 Jaws 3-D (1983)\n",
      "1487 Even Cowgirls Get the Blues (1993)\n",
      "1486 Girl in the Cadillac (1995)\n",
      "1484 Jerky Boys, The (1994)\n",
      "1481 S.F.W. (1994)\n",
      "1480 Herbie Rides Again (1974)\n",
      "897 Time Tracers (1995)\n",
      "907 Vermin (1998)\n",
      "1477 Nightwatch (1997)\n",
      "1476 Raw Deal (1948)\n",
      "1472 Visitors, The (Visiteurs, Les) (1993)\n",
      "910 Nil By Mouth (1997)\n",
      "911 Twilight (1998)\n",
      "1465 Last Summer in the Hamptons (1995)\n",
      "438 Amityville 3-D (1983)\n",
      "439 Amityville: A New Generation (1993)\n",
      "1441 Moonlight and Valentino (1995)\n",
      "1442 Scarlet Letter, The (1995)\n",
      "442 Amityville Curse, The (1990)\n",
      "1447 Century (1993)\n",
      "1436 Mr. Jones (1993)\n",
      "913 Love and Death on Long Island (1997)\n",
      "1453 Angel on My Shoulder (1946)\n",
      "1454 Angel and the Badman (1947)\n",
      "1455 Outlaw, The (1943)\n",
      "1457 Love Is All There Is (1996)\n",
      "1460 Sleepover (1995)\n",
      "1461 Here Comes Cookie (1935)\n",
      "1448 My Favorite Season (1993)\n",
      "377 Heavyweights (1994)\n",
      "1366 JLG/JLG - autoportrait de dcembre (1994)\n",
      "1365 Johnny 100 Pesos (1993)\n",
      "1156 Cyclo (1995)\n",
      "1322 Metisse (Caf au Lait) (1993)\n",
      "1320 Homage (1995)\n",
      "1319 Neon Bible, The (1995)\n",
      "1318 Catwalk (1995)\n",
      "1162 Phat Beach (1996)\n",
      "1164 Zeus and Roxanne (1997)\n",
      "1165 Big Bully (1996)\n",
      "1314 Surviving the Game (1994)\n",
      "1177 Dunston Checks In (1996)\n",
      "1182 Cops and Robbersons (1994)\n",
      "1310 Walk in the Sun, A (1945)\n",
      "1309 Very Natural Thing, A (1974)\n",
      "1308 Babyfever (1994)\n",
      "1307 Carmen Miranda: Bananas Is My Business (1994)\n",
      "1213 Guilty as Sin (1993)\n",
      "314 3 Ninjas: High Noon At Mega Mountain (1998)\n",
      "1256 Designated Mourner, The (1997)\n",
      "1270 Life with Mikey (1993)\n",
      "1272 Talking About Sex (1994)\n",
      "1255 Broken English (1996)\n",
      "1274 Robocop 3 (1993)\n",
      "1254 Gone Fishin' (1997)\n",
      "1323 Wooden Man's Bride, The (Wu Kui) (1994)\n",
      "1250 Best of the Best 3: No Turning Back (1995)\n",
      "1247 Bad Girls (1994)\n",
      "1290 Country Life (1994)\n",
      "1246 Bushwhacked (1995)\n",
      "1292 Simple Wish, A (1997)\n",
      "1236 Other Voices, Other Rooms (1997)\n",
      "1230 Ready to Wear (Pret-A-Porter) (1994)\n",
      "1287 Ed (1996)\n",
      "1151 Original Gangstas (1996)\n",
      "1325 August (1996)\n",
      "1327 Captives (1994)\n",
      "368 Bio-Dome (1996)\n",
      "1076 Pagemaster, The (1994)\n",
      "1348 Every Other Weekend (1990)\n",
      "1349 Mille bolle blu (1993)\n",
      "1350 Crows and Sparrows (1949)\n",
      "1351 Lover's Knot (1996)\n",
      "1082 Female Perversions (1996)\n",
      "1352 Shadow of Angels (Schatten der Engel) (1976)\n",
      "1359 Boys in Venice (1996)\n",
      "1360 Sexual Life of the Belgians, The (1994)\n",
      "1361 Search for One-eye Jimmy, The (1996)\n",
      "1362 American Strays (1996)\n",
      "1363 Leopard Son, The (1996)\n",
      "1364 Bird of Prey (1996)\n",
      "1354 Venice/Venice (1992)\n",
      "1494 Mostro, Il (1994)\n",
      "1345 Day the Sun Turned Cold, The (Tianguo niezi) (1994)\n",
      "1083 Albino Alligator (1996)\n",
      "1329 Low Life, The (1994)\n",
      "1330 An Unforgettable Summer (1994)\n",
      "1146 Calendar Girl (1993)\n",
      "1332 My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)\n",
      "1096 Commandments (1997)\n",
      "1334 Somebody to Love (1994)\n",
      "1343 Lotto Land (1995)\n",
      "1092 Dear God (1996)\n",
      "1337 Larger Than Life (1996)\n",
      "1338 Two Deaths (1995)\n",
      "1339 Stefano Quantestorie (1993)\n",
      "1340 Crude Oasis, The (1995)\n",
      "1341 Hedd Wyn (1992)\n",
      "1342 Convent, The (Convento, O) (1995)\n",
      "1336 Kazaam (1996)\n",
      "1496 Carpool (1996)\n",
      "1489 Chasers (1994)\n",
      "861 Nosferatu a Venezia (1986)\n",
      "1627 Wife, The (1995)\n",
      "1629 Nico Icon (1995)\n",
      "1630 Silence of the Palace, The (Saimt el Qusur) (1994)\n",
      "1631 Slingshot, The (1993)\n",
      "1632 Land and Freedom (Tierra y libertad) (1995)\n",
      "1633  kldum klaka (Cold Fever) (1994)\n",
      "1626 Nobody Loves Me (Keiner liebt mich) (1994)\n",
      "1634 Etz Hadomim Tafus (Under the Domin Tree) (1994)\n",
      "1636 Brothers in Trouble (1995)\n",
      "1637 Girls Town (1996)\n",
      "1638 Normal Life (1996)\n",
      "1640 Eighth Day, The (1996)\n",
      "1641 Dadetown (1995)\n",
      "1643 Angel Baby (1995)\n",
      "1635 Two Friends (1986) \n",
      "757 Across the Sea of Time (1995)\n",
      "1625 Nightwatch (1997)\n",
      "1621 Butterfly Kiss (1995)\n",
      "1596 Nemesis 2: Nebula (1995)\n",
      "777 Castle Freak (1995)\n",
      "1601 Office Killer (1997)\n",
      "1603 Angela (1995)\n",
      "1604 He Walked by Night (1948)\n",
      "1605 Love Serenade (1996)\n",
      "1624 Hush (1998)\n",
      "1606 Deceiver (1997)\n",
      "1609 B*A*P*S (1997)\n",
      "1610 Truth or Consequences, N.M. (1997)\n",
      "1611 Intimate Relations (1996)\n",
      "1614 Reluctant Debutante, The (1958)\n",
      "1618 King of New York (1990)\n",
      "1619 All Things Fair (1996)\n",
      "1608 Buddy (1997)\n",
      "870 Touch (1997)\n",
      "677 Fire on the Mountain (1996)\n",
      "599 Police Story 4: Project S (Chao ji ji hua) (1993)\n",
      "1667 Next Step, The (1995)\n",
      "1668 Wedding Bell Blues (1996)\n",
      "1669 MURDER and murder (1996)\n",
      "1670 Tainted (1998)\n",
      "1671 Further Gesture, A (1996)\n",
      "1672 Kika (1993)\n",
      "1666 Ripe (1996)\n",
      "1673 Mirage (1995)\n",
      "1675 Sunchaser, The (1996)\n",
      "1676 War at Home, The (1996)\n",
      "1677 Sweet Nothing (1995)\n",
      "1678 Mat' i syn (1997)\n",
      "1679 B. Monkey (1998)\n",
      "1680 Sliding Doors (1998)\n",
      "1674 Mamma Roma (1962)\n",
      "545 Vampire in Brooklyn (1995)\n",
      "1665 Brother's Kiss, A (1997)\n",
      "1661 New Age, The (1994)\n",
      "1644 Sudden Manhattan (1996)\n",
      "1645 Butcher Boy, The (1998)\n",
      "1647 Hana-bi (1997)\n",
      "1648 Niagara, Niagara (1997)\n",
      "1649 Big One, The (1997)\n",
      "598 Big Squeeze, The (1996)\n",
      "1663 Nothing Personal (1995)\n",
      "1652 Temptress Moon (Feng Yue) (1996)\n",
      "1655 Favor, The (1994)\n",
      "1656 Little City (1998)\n",
      "1657 Target (1995)\n",
      "1659 Getting Away With Murder (1996)\n",
      "1660 Small Faces (1995)\n",
      "594 Heavy (1995)\n",
      "1654 Chairman of the Board (1998)\n",
      "1594 Everest (1998)\n",
      "1595 Shopping (1994)\n",
      "1588 Salut cousin! (1996)\n",
      "1681 You So Crazy (1994)\n",
      "1543 Johns (1996)\n",
      "1545 Frankie Starlight (1995)\n",
      "1546 Shadows (Cienie) (1988)\n",
      "1548 The Courtyard (1995)\n",
      "1549 Dream Man (1995)\n",
      "1539 Being Human (1993)\n",
      "1550 Destiny Turns on the Radio (1995)\n",
      "830 Power 98 (1995)\n",
      "1552 Hunted, The (1995)\n",
      "803 Heaven & Earth (1993)\n",
      "1555 Secret Adventures of Tom Thumb, The (1993)\n",
      "1556 Condition Red (1995)\n",
      "1557 Yankee Zulu (1994)\n",
      "1551 Glass Shield, The (1994)\n",
      "1559 Hostile Intentions (1994)\n",
      "852 Bloody Child, The (1996)\n",
      "1532 Foreign Student (1994)\n",
      "1502 Naked in New York (1994)\n",
      "1507 Three Lives and Only One Death (1996)\n",
      "1508 Babysitter, The (1995)\n",
      "1509 Getting Even with Dad (1994)\n",
      "1510 Mad Dog Time (1996)\n",
      "1513 Sprung (1997)\n",
      "1538 All Over Me (1997)\n",
      "1520 Fear, The (1995)\n",
      "858 Amityville: Dollhouse (1996)\n",
      "1522 Trial by Jury (1994)\n",
      "857 Paris Was a Woman (1995)\n",
      "1528 Nowhere (1997)\n",
      "1529 Underground (1995)\n",
      "1530 Jefferson in Paris (1995)\n",
      "1521 Mr. Wonderful (1993)\n",
      "1590 To Have, or Not (1995)\n",
      "1257 Designated Mourner, The (1997)\n",
      "103 All Dogs Go to Heaven 2 (1996)\n",
      "1587 Terror in a Texas Town (1958)\n",
      "1586 Lashou shentan (1992)\n",
      "784 Beyond Bedlam (1993)\n",
      "1584 Symphonie pastorale, La (1946)\n",
      "788 Relative Fear (1994)\n",
      "1583 Invitation, The (Zaproszenie) (1986)\n",
      "1582 T-Men (1947)\n",
      "1581 Woman in Question, The (1950)\n",
      "1580 Liebelei (1933)\n",
      "1579 Baton Rouge (1988)\n",
      "1578 Collectionneuse, La (1967)\n",
      "104 Theodore Rex (1995)\n",
      "1576 Hungarian Fairy Tale, A (1987)\n",
      "1575 I, Worst of All (Yo, la peor de todas) (1990)\n",
      "1577 Death in the Garden (Mort en ce jardin, La) (1956)\n",
      "1574 Pharaoh's Army (1995)\n",
      "1572 Wend Kuuni (God's Gift) (1982)\n",
      "1571 Touki Bouki (Journey of the Hyena) (1973)\n",
      "1570 Quartier Mozart (1992)\n",
      "1569 Vie est belle, La (Life is Rosey) (1987)\n",
      "1561 Tigrero: A Film That Was Never Made (1994)\n",
      "1568 Vermont Is For Lovers (1992)\n",
      "1567 Careful (1992)\n",
      "1566 Man from Down Under, The (1943)\n",
      "1565 Daens (1992)\n",
      "1564 To Cross the Rubicon (1991)\n",
      "1563 Promise, The (Versprechen, Das) (1994)\n",
      "1562 Eye of Vichy, The (Oeil de Vichy, L') (1993)\n",
      "383 Flintstones, The (1994)\n",
      "758 Lawnmower Man 2: Beyond Cyberspace (1996)\n",
      "931 Island of Dr. Moreau, The (1996)\n",
      "997 Stuart Saves His Family (1995)\n",
      "1207 Jade (1995)\n",
      "590 Hellraiser: Bloodline (1996)\n",
      "983 Rich Man's Wife, The (1996)\n",
      "1013 Anaconda (1997)\n",
      "801 Air Up There, The (1994)\n",
      "564 Tales from the Hood (1995)\n",
      "1303 Getaway, The (1994)\n",
      "700 Miami Rhapsody (1995)\n",
      "540 Money Train (1995)\n",
      "1225 Angus (1995)\n",
      "36 Mad Love (1995)\n",
      "457 Free Willy 3: The Rescue (1997)\n",
      "1034 Quest, The (1996)\n",
      "1229 Poison Ivy II (1995)\n",
      "1419 Highlander III: The Sorcerer (1994)\n",
      "669 Body Parts (1991)\n",
      "1215 Barb Wire (1996)\n",
      "1291 Celtic Pride (1996)\n",
      "787 Roommates (1995)\n",
      "734 Made in America (1993)\n",
      "1171 Wild Reeds (1994)\n",
      "388 Beverly Hills Cop III (1994)\n",
      "577 Coneheads (1993)\n",
      "782 Little Odessa (1994)\n",
      "976 Solo (1996)\n",
      "991 Keys to Tulsa (1997)\n",
      "832 Bogus (1996)\n",
      "1054 Mr. Wrong (1996)\n",
      "456 Beverly Hills Ninja (1997)\n",
      "688 Leave It to Beaver (1997)\n",
      "440 Amityville II: The Possession (1982)\n",
      "767 Addiction, The (1995)\n",
      "1040 Two if by Sea (1996)\n",
      "1300 'Til There Was You (1997)\n",
      "933 Funeral, The (1996)\n",
      "572 Blown Away (1994)\n",
      "375 Showgirls (1995)\n",
      "406 Thinner (1996)\n",
      "743 Crow: City of Angels, The (1996)\n",
      "1089 Speed 2: Cruise Control (1997)\n",
      "876 Money Talks (1997)\n",
      "1087 Bloodsport 2 (1995)\n",
      "1232 Madonna: Truth or Dare (1991)\n",
      "1184 Endless Summer 2, The (1994)\n",
      "374 Mighty Morphin Power Rangers: The Movie (1995)\n",
      "548 NeverEnding Story III, The (1994)\n",
      "37 Nadja (1994)\n",
      "1180 I Love Trouble (1994)\n",
      "1179 Man of the House (1995)\n",
      "1444 That Darn Cat! (1965)\n",
      "901 Mr. Magoo (1997)\n",
      "556 Wild Bill (1995)\n",
      "1037 Grease 2 (1982)\n",
      "563 Stephen King's The Langoliers (1995)\n",
      "667 Audrey Rose (1977)\n",
      "1145 Blue Chips (1994)\n",
      "687 McHale's Navy (1997)\n",
      "826 Phantom, The (1996)\n",
      "940 Airheads (1994)\n",
      "398 Super Mario Bros. (1993)\n",
      "120 Striptease (1996)\n",
      "859 April Fool's Day (1986)\n",
      "122 Cable Guy, The (1996)\n",
      "769 Congo (1995)\n",
      "831 Escape from L.A. (1996)\n",
      "158 Weekend at Bernie's (1989)\n",
      "1479 Reckless (1995)\n",
      "912 U.S. Marshalls (1998)\n",
      "860 Believers, The (1987)\n",
      "441 Amityville Horror, The (1979)\n",
      "1002 Pest, The (1997)\n",
      "996 Big Green, The (1995)\n",
      "376 Houseguest (1994)\n",
      "1415 Next Karate Kid, The (1994)\n",
      "1399 Stranger in the House (1997)\n",
      "1214 In the Realm of the Senses (Ai no corrida) (1976)\n",
      "1140 Road to Wellville, The (1994)\n",
      "1227 Awfully Big Adventure, An (1995)\n",
      "1222 Judgment Night (1993)\n",
      "78 Free Willy (1993)\n",
      "759 Fair Game (1995)\n",
      "1305 National Lampoon's Senior Trip (1995)\n",
      "948 Booty Call (1997)\n",
      "930 Chain Reaction (1996)\n",
      "834 Halloween: The Curse of Michael Myers (1995)\n",
      "571 Another Stakeout (1993)\n",
      "400 Little Rascals, The (1994)\n",
      "719 Canadian Bacon (1994)\n",
      "1209 Mixed Nuts (1994)\n",
      "779 Drop Zone (1994)\n",
      "1049 House Arrest (1996)\n",
      "877 Excess Baggage (1997)\n",
      "683 Rocket Man (1997)\n",
      "130 Kansas City (1996)\n",
      "1139 Hackers (1995)\n",
      "1132 Feeling Minnesota (1996)\n",
      "849 Days of Thunder (1990)\n",
      "397 Striking Distance (1993)\n",
      "542 Pocahontas (1995)\n",
      "1435 Steal Big, Steal Little (1995)\n",
      "1231 Marked for Death (1990)\n",
      "1289 Jack and Sarah (1995)\n",
      "1379 Love and Other Catastrophes (1996)\n",
      "560 Kid in King Arthur's Court, A (1995)\n",
      "1003 That Darn Cat! (1997)\n",
      "1205 Secret Agent, The (1996)\n",
      "1032 Little Big League (1994)\n",
      "1057 Pallbearer, The (1996)\n",
      "706 Bad Moon (1996)\n",
      "725 Exit to Eden (1994)\n",
      "804 Jimmy Hollywood (1994)\n",
      "1185 In the Army Now (1994)\n",
      "891 Bent (1997)\n",
      "890 Mortal Kombat: Annihilation (1997)\n",
      "1102 Two Much (1996)\n",
      "1072 Pyromaniac's Love Story, A (1995)\n",
      "871 Vegas Vacation (1997)\n",
      "139 Love Bug, The (1969)\n",
      "412 Very Brady Sequel, A (1996)\n",
      "21 Muppet Treasure Island (1996)\n",
      "575 City Slickers II: The Legend of Curly's Gold (1994)\n",
      "771 Johnny Mnemonic (1995)\n",
      "760 Screamers (1995)\n",
      "1090 Sliver (1993)\n",
      "988 Beautician and the Beast, The (1997)\n",
      "1411 Barbarella (1968)\n",
      "364 Ace Ventura: When Nature Calls (1995)\n",
      "862 Jingle All the Way (1996)\n",
      "977 Substitute, The (1996)\n",
      "829 Fled (1996)\n",
      "395 Robin Hood: Men in Tights (1993)\n",
      "105 Sgt. Bilko (1996)\n",
      "551 Lord of Illusions (1995)\n",
      "828 Alaska (1996)\n",
      "1263 Foxfire (1996)\n",
      "1015 Shiloh (1997)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224 Scout, The (1994)\n",
      "998 Cabin Boy (1994)\n",
      "386 Addams Family Values (1993)\n",
      "243 Jungle2Jungle (1997)\n",
      "586 Terminal Velocity (1994)\n",
      "892 Flubber (1997)\n",
      "1178 Major Payne (1994)\n",
      "982 Maximum Risk (1996)\n",
      "264 Mimic (1997)\n",
      "1183 Cowboy Way, The (1994)\n",
      "938 Smile Like Yours, A (1997)\n",
      "29 Batman Forever (1995)\n",
      "1023 Fathers' Day (1997)\n",
      "1095 High School High (1996)\n",
      "384 Naked Gun 33 1/3: The Final Insult (1994)\n",
      "145 Lawnmower Man, The (1992)\n",
      "231 Batman Returns (1992)\n",
      "791 Baby-Sitters Club, The (1995)\n",
      "1376 Meet Wally Sparks (1997)\n",
      "247 Turbo: A Power Rangers Movie (1997)\n",
      "1108 Feast of July (1995)\n",
      "1333 Midnight Dancers (Sibak) (1994)\n",
      "1031 Lassie (1994)\n",
      "1088 Double Team (1997)\n",
      "1527 Senseless (1998)\n",
      "1346 Dingo (1992)\n",
      "1324 Loaded (1994)\n",
      "1470 Gumby: The Movie (1995)\n",
      "1392 Locusts, The (1997)\n",
      "263 Steel (1997)\n",
      "1283 Out to Sea (1997)\n",
      "978 Heaven's Prisoners (1996)\n",
      "415 Apple Dumpling Gang, The (1975)\n",
      "1249 For Love or Money (1993)\n",
      "1241 Van, The (1996)\n",
      "994 Last Time I Committed Suicide, The (1997)\n",
      "407 Spy Hard (1996)\n",
      "1079 Joe's Apartment (1996)\n",
      "1000 Lightning Jack (1994)\n",
      "1234 Chairman of the Board (1998)\n",
      "1212 Flesh and Bone (1993)\n",
      "1380 Hollow Reed (1996)\n",
      "1381 Losing Chase (1996)\n",
      "1091 Pete's Dragon (1977)\n",
      "951 Indian in the Cupboard, The (1995)\n",
      "1244 Metro (1997)\n",
      "358 Spawn (1997)\n",
      "450 Star Trek V: The Final Frontier (1989)\n",
      "254 Batman & Robin (1997)\n",
      "795 Richie Rich (1994)\n",
      "824 Great White Hype, The (1996)\n",
      "112 Flipper (1996)\n",
      "1206 Amos & Andrew (1993)\n",
      "819 Eddie (1996)\n",
      "1273 Color of Night (1994)\n",
      "1001 Stupids, The (1996)\n",
      "1478 Dead Presidents (1995)\n",
      "454 Bastard Out of Carolina (1996)\n",
      "569 Wolf (1994)\n",
      "738 Threesome (1994)\n",
      "1188 Young Guns II (1990)\n",
      "820 Space Jam (1996)\n",
      "722 Nine Months (1995)\n",
      "873 Picture Perfect (1997)\n",
      "261 Air Bud (1997)\n",
      "35 Free Willy 2: The Adventure Home (1995)\n",
      "986 Turbulence (1997)\n",
      "555 White Man's Burden (1995)\n",
      "452 Jaws 2 (1978)\n",
      "1400 Picture Bride (1995)\n",
      "1199 Cemetery Man (Dellamorte Dellamore) (1994)\n",
      "565 Village of the Damned (1995)\n",
      "1127 Truman Show, The (1998)\n",
      "816 Candyman: Farewell to the Flesh (1995)\n",
      "810 Shadow, The (1994)\n",
      "391 Last Action Hero (1993)\n",
      "1052 Dracula: Dead and Loving It (1995)\n",
      "926 Down Periscope (1996)\n",
      "1228 Under Siege 2: Dark Territory (1995)\n",
      "1030 Beverly Hillbillies, The (1993)\n",
      "786 Perez Family, The (1995)\n",
      "678 Volcano (1997)\n",
      "235 Mars Attacks! (1996)\n",
      "541 Mortal Kombat (1995)\n",
      "1078 Oliver & Company (1988)\n",
      "1258 Trial and Error (1997)\n",
      "672 Candyman (1992)\n",
      "674 Cat People (1982)\n",
      "539 Mouse Hunt (1997)\n",
      "1047 Multiplicity (1996)\n",
      "765 Boomerang (1992)\n",
      "823 Mulholland Falls (1996)\n",
      "80 Hot Shots! Part Deux (1993)\n",
      "783 Milk Money (1994)\n",
      "38 Net, The (1995)\n",
      "920 Two Bits (1995)\n",
      "950 Georgia (1995)\n",
      "1216 Kissed (1996)\n",
      "668 Blood Beach (1981)\n",
      "1295 Kicked in the Head (1997)\n",
      "1239 Cutthroat Island (1995)\n",
      "18 White Balloon, The (1995)\n",
      "1248 Blink (1994)\n",
      "1386 Tetsuo II: Body Hammer (1992)\n",
      "1311 Waiting to Exhale (1995)\n",
      "574 Boxing Helena (1993)\n",
      "1284 Before and After (1996)\n",
      "1438 Panther (1995)\n",
      "666 Blood For Dracula (Andy Warhol's Dracula) (1974)\n",
      "1252 Contempt (Mpris, Le) (1963)\n",
      "869 Fools Rush In (1997)\n",
      "704 House of the Spirits, The (1993)\n",
      "1501 Prisoner of the Mountains (Kavkazsky Plennik) (1996)\n",
      "838 In the Line of Duty 2 (1987)\n",
      "1347 Ballad of Narayama, The (Narayama Bushiko) (1958)\n",
      "1369 Forbidden Christ, The (Cristo proibito, Il) (1950)\n",
      "1094 Thin Line Between Love and Hate, A (1996)\n",
      "881 Money Talks (1997)\n",
      "885 Phantoms (1998)\n",
      "889 Tango Lesson, The (1997)\n",
      "827 Daylight (1996)\n",
      "351 Prophecy II, The (1998)\n",
      "985 Blood & Wine (1997)\n",
      "110 Operation Dumbo Drop (1995)\n",
      "798 Bad Company (1995)\n",
      "1597 Romper Stomper (1992)\n",
      "146 Unhook the Stars (1996)\n",
      "1598 City of Industry (1997)\n",
      "1440 Above the Rim (1994)\n",
      "1181 Low Down Dirty Shame, A (1994)\n",
      "1081 Curdled (1996)\n",
      "1174 Caught (1996)\n",
      "260 Event Horizon (1997)\n",
      "413 Tales from the Crypt Presents: Bordello of Blood (1996)\n",
      "444 Blob, The (1958)\n",
      "623 Angels in the Outfield (1994)\n",
      "167 Private Benjamin (1980)\n",
      "756 Father of the Bride Part II (1995)\n",
      "764 If Lucy Fell (1996)\n",
      "362 Blues Brothers 2000 (1998)\n",
      "325 Crash (1996)\n",
      "768 Casper (1995)\n",
      "259 George of the Jungle (1997)\n",
      "728 Junior (1994)\n",
      "1163 Portrait of a Lady, The (1996)\n",
      "335 How to Be a Player (1997)\n",
      "841 Glimmer Man, The (1996)\n",
      "370 Mary Reilly (1996)\n",
      "717 Juror, The (1996)\n",
      "401 Brady Bunch Movie, The (1995)\n",
      "1219 Goofy Movie, A (1995)\n",
      "1105 Firestorm (1998)\n",
      "979 Trigger Effect, The (1996)\n",
      "1071 Party Girl (1995)\n",
      "808 Program, The (1993)\n",
      "878 That Darn Cat! (1997)\n",
      "989 Cats Don't Dance (1997)\n",
      "363 Sudden Death (1995)\n",
      "785 Only You (1994)\n",
      "336 Playing God (1997)\n",
      "726 Fluke (1995)\n",
      "369 Black Sheep (1996)\n",
      "1285 Princess Caraboo (1994)\n",
      "967 Little Lord Fauntleroy (1936)\n",
      "1518 Losing Isaiah (1995)\n",
      "1006 Until the End of the World (Bis ans Ende der Welt) (1991)\n",
      "840 Last Man Standing (1996)\n",
      "554 Waterworld (1995)\n",
      "138 D3: The Mighty Ducks (1996)\n",
      "422 Aladdin and the King of Thieves (1996)\n",
      "1074 Reality Bites (1994)\n",
      "974 Eye for an Eye (1996)\n",
      "797 Timecop (1994)\n",
      "932 First Kid (1996)\n",
      "802 Hard Target (1993)\n",
      "576 Cliffhanger (1993)\n",
      "929 Harriet the Spy (1996)\n",
      "1280 Gang Related (1997)\n",
      "1066 Balto (1995)\n",
      "1439 Jason's Lyric (1994)\n",
      "1335 American Buffalo (1996)\n",
      "1208 Kiss of Death (1995)\n",
      "1475 Bhaji on the Beach (1993)\n",
      "1100 What Happened Was... (1994)\n",
      "1434 Shooting Fish (1997)\n",
      "592 True Crime (1995)\n",
      "1471 Hideaway (1995)\n",
      "1271 North (1994)\n",
      "681 Wishmaster (1997)\n",
      "1253 Tie That Binds, The (1995)\n",
      "252 Lost World: Jurassic Park, The (1997)\n",
      "411 Nutty Professor, The (1996)\n",
      "43 Disclosure (1994)\n",
      "680 Kull the Conqueror (1997)\n",
      "338 Bean (1997)\n",
      "323 Dante's Peak (1997)\n",
      "552 Species (1995)\n",
      "749 MatchMaker, The (1997)\n",
      "225 101 Dalmatians (1996)\n",
      "908 Half Baked (1998)\n",
      "975 Fear (1996)\n",
      "696 City Hall (1996)\n",
      "928 Craft, The (1996)\n",
      "1060 Adventures of Pinocchio, The (1996)\n",
      "1068 Star Maker, The (Uomo delle stelle, L') (1995)\n",
      "1133 Escape to Witch Mountain (1975)\n",
      "1120 I'm Not Rappaport (1996)\n",
      "731 Corrina, Corrina (1994)\n",
      "914 Wild Things (1998)\n",
      "352 Spice World (1997)\n",
      "1161 Palookaville (1996)\n",
      "665 Alien 3 (1992)\n",
      "561 Mary Shelley's Frankenstein (1994)\n",
      "875 She's So Lovely (1997)\n",
      "1217 Assassins (1995)\n",
      "62 Stargate (1994)\n",
      "934 Preacher's Wife, The (1996)\n",
      "309 Deceiver (1997)\n",
      "476 First Wives Club, The (1996)\n",
      "1110 Tank Girl (1995)\n",
      "266 Kull the Conqueror (1997)\n",
      "353 Deep Rising (1998)\n",
      "843 Shaggy Dog, The (1959)\n",
      "579 Fatal Instinct (1993)\n",
      "894 Home Alone 3 (1997)\n",
      "106 Diabolique (1996)\n",
      "567 Wes Craven's New Nightmare (1994)\n",
      "281 River Wild, The (1994)\n",
      "229 Star Trek III: The Search for Spock (1984)\n",
      "773 Mute Witness (1994)\n",
      "821 Mrs. Winterbourne (1996)\n",
      "1036 Drop Dead Fred (1991)\n",
      "1135 Doors, The (1991)\n",
      "426 Transformers: The Movie, The (1986)\n",
      "63 Santa Clause, The (1994)\n",
      "864 My Fellow Americans (1996)\n",
      "585 Son in Law (1993)\n",
      "460 Crossing Guard, The (1995)\n",
      "240 Beavis and Butt-head Do America (1996)\n",
      "1267 Clockers (1995)\n",
      "1018 Tie Me Up! Tie Me Down! (1990)\n",
      "941 With Honors (1994)\n",
      "373 Judge Dredd (1995)\n",
      "712 Tin Men (1987)\n",
      "342 Man Who Knew Too Little, The (1997)\n",
      "1553 Underneath, The (1995)\n",
      "1602 Price Above Rubies, A (1998)\n",
      "1275 Killer (Bulletproof Heart) (1994)\n",
      "1474 Nina Takes a Lover (1994)\n",
      "935 Paradise Road (1997)\n",
      "1511 Children of the Revolution (1996)\n",
      "1268 Bitter Moon (1992)\n",
      "695 Kicking and Screaming (1995)\n",
      "446 Burnt Offerings (1976)\n",
      "1279 Wild America (1997)\n",
      "1237 Twisted (1996)\n",
      "1356 Ed's Next Move (1996)\n",
      "1055 Simple Twist of Fate, A (1994)\n",
      "1600 Guantanamera (1994)\n",
      "1331 Last Klezmer: Leopold Kozlowski, His Life and Music, The (1995)\n",
      "774 Prophecy, The (1995)\n",
      "396 Serial Mom (1994)\n",
      "796 Speechless (1994)\n",
      "1026 Lay of the Land, The (1997)\n",
      "1607 Hurricane Streets (1998)\n",
      "1357 For the Moment (1994)\n",
      "809 Rising Sun (1993)\n",
      "1043 Rent-a-Kid (1995)\n",
      "1589 Schizopolis (1996)\n",
      "817 Frisk (1995)\n",
      "822 Faces (1968)\n",
      "992 Head Above Water (1996)\n",
      "1299 Penny Serenade (1941)\n",
      "846 To Gillian on Her 37th Birthday (1996)\n",
      "1592 Magic Hour, The (1998)\n",
      "818 Girl 6 (1996)\n",
      "1431 Legal Deceit (1997)\n",
      "1413 Street Fighter (1994)\n",
      "1198 Purple Noon (1960)\n",
      "1112 Cobb (1994)\n",
      "1658 Substance of Fire, The (1996)\n",
      "1196 Savage Nights (Nuits fauves, Les) (1992)\n",
      "1402 Ciao, Professore! (1993)\n",
      "1403 Caro Diario (Dear Diary) (1994)\n",
      "1128 Heidi Fleiss: Hollywood Madam (1995) \n",
      "34 Doom Generation, The (1995)\n",
      "1406 When Night Is Falling (1995)\n",
      "670 Body Snatchers (1993)\n",
      "1410 Harlem (1993)\n",
      "1141 War Room, The (1993)\n",
      "1446 Bye Bye, Love (1995)\n",
      "1157 Relic, The (1997)\n",
      "1391 For Ever Mozart (1996)\n",
      "1427 Drunks (1995)\n",
      "339 Mad City (1997)\n",
      "1377 Hotel de Love (1996)\n",
      "40 To Wong Foo, Thanks for Everything! Julie Newmar (1995)\n",
      "1167 Sum of Us, The (1994)\n",
      "573 Body Snatchers (1993)\n",
      "449 Star Trek: The Motion Picture (1979)\n",
      "625 Sword in the Stone, The (1963)\n",
      "595 Fan, The (1996)\n",
      "85 Ref, The (1994)\n",
      "1028 Grumpier Old Men (1995)\n",
      "3 Four Rooms (1995)\n",
      "562 Quick and the Dead, The (1995)\n",
      "1118 Up in Smoke (1978)\n",
      "1025 Fire Down Below (1997)\n",
      "330 187 (1997)\n",
      "723 Boys on the Side (1995)\n",
      "984 Shadow Conspiracy (1997)\n",
      "355 Sphere (1998)\n",
      "322 Murder at 1600 (1997)\n",
      "578 Demolition Man (1993)\n",
      "546 Broken Arrow (1996)\n",
      "232 Young Guns (1988)\n",
      "679 Conan the Barbarian (1981)\n",
      "94 Home Alone (1990)\n",
      "635 Fog, The (1980)\n",
      "1265 Star Maps (1997)\n",
      "903 Afterglow (1997)\n",
      "472 Dragonheart (1996)\n",
      "780 Dumb & Dumber (1994)\n",
      "597 Eraser (1996)\n",
      "583 Romeo Is Bleeding (1993)\n",
      "1033 Homeward Bound II: Lost in San Francisco (1996)\n",
      "1014 Romy and Michele's High School Reunion (1997)\n",
      "473 James and the Giant Peach (1996)\n",
      "321 Mother (1996)\n",
      "289 Evita (1996)\n",
      "872 Love Jones (1997)\n",
      "620 Chamber, The (1996)\n",
      "790 Tommy Boy (1995)\n",
      "720 First Knight (1995)\n",
      "149 Jude (1996)\n",
      "1170 Spanking the Monkey (1994)\n",
      "733 Go Fish (1994)\n",
      "1061 Evening Star, The (1996)\n",
      "41 Billy Madison (1995)\n",
      "1045 Fearless (1993)\n",
      "1220 Higher Learning (1995)\n",
      "343 Alien: Resurrection (1997)\n",
      "417 Parent Trap, The (1961)\n",
      "637 Howling, The (1981)\n",
      "1210 Virtuosity (1995)\n",
      "1048 She's the One (1996)\n",
      "245 Devil's Own, The (1997)\n",
      "952 Blue in the Face (1995)\n",
      "1041 Forget Paris (1995)\n",
      "748 Saint, The (1997)\n",
      "953 Unstrung Heroes (1995)\n",
      "1282 Grass Harp, The (1995)\n",
      "630 Great Race, The (1965)\n",
      "944 Renaissance Man (1994)\n",
      "1425 I'll Do Anything (1994)\n",
      "1011 2 Days in the Valley (1996)\n",
      "1297 Love Affair (1994)\n",
      "1426 Grace of My Heart (1996)\n",
      "1540 Amazing Panda Adventure, The (1995)\n",
      "1114 Faithful (1996)\n",
      "1035 Cool Runnings (1993)\n",
      "621 Davy Crockett, King of the Wild Frontier (1955)\n",
      "249 Austin Powers: International Man of Mystery (1997)\n",
      "84 Robert A. Heinlein's The Puppet Masters (1994)\n",
      "27 Bad Boys (1995)\n",
      "766 Man of the Year (1995)\n",
      "1107 Beyond Rangoon (1995)\n",
      "918 City of Angels (1998)\n",
      "1017 Trees Lounge (1996)\n",
      "379 Tales From the Crypt Presents: Demon Knight (1995)\n",
      "244 Smilla's Sense of Snow (1997)\n",
      "142 Bedknobs and Broomsticks (1971)\n",
      "886 Life Less Ordinary, A (1997)\n",
      "775 Something to Talk About (1995)\n",
      "800 In the Mouth of Madness (1995)\n",
      "619 Extreme Measures (1996)\n",
      "2 GoldenEye (1995)\n",
      "702 Barcelona (1994)\n",
      "1024 Mrs. Dalloway (1997)\n",
      "916 Lost in Space (1998)\n",
      "349 Hard Rain (1998)\n",
      "559 Interview with the Vampire (1994)\n",
      "737 Sirens (1994)\n",
      "53 Natural Born Killers (1994)\n",
      "102 Aristocats, The (1970)\n",
      "716 Home for the Holidays (1995)\n",
      "1296 Indian Summer (1996)\n",
      "761 Nick of Time (1995)\n",
      "290 Fierce Creatures (1997)\n",
      "532 Kama Sutra: A Tale of Love (1996)\n",
      "90 So I Married an Axe Murderer (1993)\n",
      "825 Arrival, The (1996)\n",
      "26 Brothers McMullen, The (1995)\n",
      "682 I Know What You Did Last Summer (1997)\n",
      "1053 Now and Then (1995)\n",
      "308 FairyTale: A True Story (1997)\n",
      "329 Desperate Measures (1998)\n",
      "535 Addicted to Love (1997)\n",
      "880 Soul Food (1997)\n",
      "299 Hoodlum (1997)\n",
      "640 Cook the Thief His Wife & Her Lover, The (1989)\n",
      "636 Escape from New York (1981)\n",
      "815 One Fine Day (1996)\n",
      "1316 Horse Whisperer, The (1998)\n",
      "1468 Cure, The (1995)\n",
      "1517 Race the Sun (1996)\n",
      "1302 Late Bloomers (1996)\n",
      "1405 Boy's Life 2 (1997)\n",
      "1534 Twin Town (1997)\n",
      "74 Faster Pussycat! Kill! Kill! (1965)\n",
      "280 Up Close and Personal (1996)\n",
      "1276 Sunset Park (1996)\n",
      "1462 Thieves (Voleurs, Les) (1996)\n",
      "1344 Story of Xinghua, The (1993)\n",
      "77 Firm, The (1993)\n",
      "67 Ace Ventura: Pet Detective (1994)\n",
      "755 Jumanji (1995)\n",
      "49 I.Q. (1994)\n",
      "949 How to Make an American Quilt (1995)\n",
      "220 Mirror Has Two Faces, The (1996)\n",
      "772 Kids (1995)\n",
      "294 Liar Liar (1997)\n",
      "874 Career Girls (1997)\n",
      "676 Crucible, The (1996)\n",
      "1010 Basquiat (1996)\n",
      "605 Meet Me in St. Louis (1944)\n",
      "284 Tin Cup (1996)\n",
      "972 Passion Fish (1992)\n",
      "895 Scream 2 (1997)\n",
      "627 Robin Hood: Prince of Thieves (1991)\n",
      "54 Outbreak (1995)\n",
      "337 House of Yes, The (1997)\n",
      "1117 Surviving Picasso (1996)\n",
      "278 Bed of Roses (1996)\n",
      "685 Executive Decision (1996)\n",
      "159 Basic Instinct (1992)\n",
      "946 Fox and the Hound, The (1981)\n",
      "1278 Selena (1997)\n",
      "1211 Blue Sky (1994)\n",
      "553 Walk in the Clouds, A (1995)\n",
      "39 Strange Days (1995)\n",
      "689 Jackal, The (1997)\n",
      "1046 Malice (1993)\n",
      "1469 Tom and Huck (1995)\n",
      "1038 Switchback (1997)\n",
      "312 Midnight in the Garden of Good and Evil (1997)\n",
      "118 Twister (1996)\n",
      "1051 Associate, The (1996)\n",
      "155 Dirty Dancing (1987)\n",
      "879 Peacemaker, The (1997)\n",
      "730 Queen Margot (Reine Margot, La) (1994)\n",
      "409 Jack (1996)\n",
      "217 Bram Stoker's Dracula (1992)\n",
      "16 French Twist (Gazon maudit) (1995)\n",
      "350 Fallen (1998)\n",
      "405 Mission: Impossible (1996)\n",
      "219 Nightmare on Elm Street, A (1984)\n",
      "108 Kids in the Hall: Brain Candy (1996)\n",
      "148 Ghost and the Darkness, The (1996)\n",
      "399 Three Musketeers, The (1993)\n",
      "448 Omen, The (1976)\n",
      "1077 Love and a .45 (1994)\n",
      "970 Hear My Song (1991)\n",
      "1159 Stalker (1979)\n",
      "1004 Geronimo: An American Legend (1993)\n",
      "1312 Pompatus of Love, The (1996)\n",
      "1394 Swept from the Sea (1997)\n",
      "360 Wonderland (1997)\n",
      "1262 Walking and Talking (1996)\n",
      "536 Ponette (1996)\n",
      "348 Desperate Measures (1998)\n",
      "947 Big Blue, The (Grand bleu, Le) (1988)\n",
      "1042 Just Cause (1995)\n",
      "1113 Mrs. Parker and the Vicious Circle (1994)\n",
      "812 Andre (1994)\n",
      "458 Nixon (1995)\n",
      "17 From Dusk Till Dawn (1996)\n",
      "658 Pump Up the Volume (1990)\n",
      "762 Beautiful Girls (1996)\n",
      "866 Michael (1996)\n",
      "371 Bridges of Madison County, The (1995)\n",
      "380 Star Trek: Generations (1994)\n",
      "389 Black Beauty (1994)\n",
      "72 Mask, The (1994)\n",
      "662 Somewhere in Time (1980)\n",
      "1277 Set It Off (1996)\n",
      "233 Under Siege (1992)\n",
      "550 Die Hard: With a Vengeance (1995)\n",
      "1059 Don't Be a Menace to South Central While Drinking Your Juice in the Hood (1996)\n",
      "622 Swiss Family Robinson (1960)\n",
      "570 Wyatt Earp (1994)\n",
      "781 French Kiss (1995)\n",
      "73 Maverick (1994)\n",
      "1240 Ghost in the Shell (Kokaku kidotai) (1995)\n",
      "1195 Strawberry and Chocolate (Fresa y chocolate) (1993)\n",
      "1503 Gold Diggers: The Secret of Bear Mountain (1995)\n",
      "999 Clean Slate (1994)\n",
      "1154 Alphaville (1965)\n",
      "980 Mother Night (1996)\n",
      "1148 Tom & Viv (1994)\n",
      "1056 Cronos (1992)\n",
      "1116 Mark of Zorro, The (1940)\n",
      "390 Fear of a Black Hat (1993)\n",
      "1281 Manny & Lo (1996)\n",
      "698 Browning Version, The (1994)\n",
      "271 Starship Troopers (1997)\n",
      "581 Kalifornia (1993)\n",
      "715 To Die For (1995)\n",
      "624 Three Caballeros, The (1945)\n",
      "596 Hunchback of Notre Dame, The (1996)\n",
      "905 Great Expectations (1998)\n",
      "960 Naked (1993)\n",
      "1315 Inventing the Abbotts (1997)\n",
      "319 Everyone Says I Love You (1996)\n",
      "883 Telling Lies in America (1997)\n",
      "1134 Get on the Bus (1996)\n",
      "593 Stalingrad (1993)\n",
      "557 Farinelli: il castrato (1994)\n",
      "1085 Carried Away (1996)\n",
      "123 Frighteners, The (1996)\n",
      "1187 Switchblade Sisters (1975)\n",
      "1109 Death and the Maiden (1994)\n",
      "324 Lost Highway (1997)\n",
      "291 Absolute Power (1997)\n",
      "629 Victor/Victoria (1982)\n",
      "5 Copycat (1995)\n",
      "990 Anna Karenina (1997)\n",
      "754 Red Corner (1997)\n",
      "1218 Friday (1995)\n",
      "365 Powder (1995)\n",
      "140 Homeward Bound: The Incredible Journey (1993)\n",
      "842 Pollyanna (1960)\n",
      "1221 When a Man Loves a Woman (1994)\n",
      "744 Michael Collins (1996)\n",
      "477 Matilda (1996)\n",
      "906 Oscar & Lucinda (1997)\n",
      "925 Unforgettable (1996)\n",
      "1009 Stealing Beauty (1996)\n",
      "128 Supercop (1992)\n",
      "1245 Gridlock'd (1997)\n",
      "468 Rudy (1993)\n",
      "44 Dolores Claiborne (1994)\n",
      "226 Die Hard 2 (1990)\n",
      "212 Unbearable Lightness of Being, The (1988)\n",
      "410 Kingpin (1996)\n",
      "445 Body Snatcher, The (1945)\n",
      "295 Breakdown (1997)\n",
      "327 Cop Land (1997)\n",
      "279 Once Upon a Time... When We Were Colored (1995)\n",
      "393 Mrs. Doubtfire (1993)\n",
      "274 Sabrina (1995)\n",
      "255 My Best Friend's Wedding (1997)\n",
      "522 Down by Law (1986)\n",
      "544 Things to Do in Denver when You're Dead (1995)\n",
      "752 Replacement Killers, The (1998)\n",
      "403 Batman (1989)\n",
      "455 Jackie Chan's First Strike (1996)\n",
      "739 Pretty Woman (1990)\n",
      "239 Sneakers (1992)\n",
      "214 Pink Floyd - The Wall (1982)\n",
      "833 Bulletproof (1996)\n",
      "671 Bride of Frankenstein (1935)\n",
      "109 Mystery Science Theater 3000: The Movie (1996)\n",
      "366 Dangerous Minds (1995)\n",
      "227 Star Trek VI: The Undiscovered Country (1991)\n",
      "721 Mallrats (1995)\n",
      "326 G.I. Jane (1997)\n",
      "501 Dumbo (1941)\n",
      "650 Seventh Seal, The (Sjunde inseglet, Det) (1957)\n",
      "727 Immortal Beloved (1994)\n",
      "101 Heavy Metal (1981)\n",
      "332 Kiss the Girls (1997)\n",
      "751 Tomorrow Never Dies (1997)\n",
      "13 Mighty Aphrodite (1995)\n",
      "201 Evil Dead II (1987)\n",
      "218 Cape Fear (1991)\n",
      "1450 Golden Earrings (1947)\n",
      "1445 Ladybird Ladybird (1994)\n",
      "1058 War, The (1994)\n",
      "1150 Last Dance (1996)\n",
      "1421 My Crazy Life (Mi vida loca) (1993)\n",
      "547 Young Poisoner's Handbook, The (1995)\n"
     ]
    }
   ],
   "source": [
    "ctr = 0;\n",
    "for index in np.argsort(popularity_recsys.getModel()[0]):\n",
    "    if(ctr!=1000):\n",
    "        print(moviesDF.loc[index, 'movieID'], moviesDF.loc[index, 'movieTitle'])\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robin Hood: Men in Tights (1993)\n",
      "          94: Home Alone (1990)\n",
      "          67: Ace Ventura: Pet Detective (1994)\n",
      "         388: Beverly Hills Cop III (1994)\n",
      "         386: Addams Family Values (1993)\n",
      "          80: Hot Shots! Part Deux (1993)\n",
      "\n",
      "Batman Returns (1992)\n",
      "         403: Batman (1989)\n",
      "          29: Batman Forever (1995)\n",
      "          62: Stargate (1994)\n",
      "         550: Die Hard: With a Vengeance (1995)\n",
      "         385: True Lies (1994)\n",
      "\n",
      "Home Alone (1990)\n",
      "         393: Mrs. Doubtfire (1993)\n",
      "          67: Ace Ventura: Pet Detective (1994)\n",
      "          63: Santa Clause, The (1994)\n",
      "         403: Batman (1989)\n",
      "          82: Jurassic Park (1993)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#395-1 Robin Hood: Men in Tights (1993)\n",
    "#231-1 Batman Returns (1992)\n",
    "#94-1 Home Alone (1990)\n",
    "\n",
    "item_similarity = item_item_similarity(rating_df, num_users, num_items)\n",
    "\n",
    "l = [394, 230, 93]\n",
    "\n",
    "for index in l:\n",
    "    print(moviesDF.loc[index, 'movieTitle'])\n",
    "    similar_movies = ((-item_similarity)[index].argsort()[1:6])\n",
    "    for movies in similar_movies:\n",
    "        print('%12s: %12s' % (moviesDF.loc[movies, 'movieID'], moviesDF.loc[movies, 'movieTitle']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Yes. These similaarities are reasonable because the returened movies are indeed similar to the chosen ones. For example the returned movies for batman are other batmane movies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 [GRAD ONLY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants for validation only\n",
    "ROW_NUM = 943\n",
    "COL_NUM = 1682\n",
    "RATING_COL = 'rating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
    "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
    "    try:\n",
    "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    except:\n",
    "        print('dataPreprocessor function has error')\n",
    "        return\n",
    "    try:\n",
    "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_df = testDataPreprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testPopularityRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    popularity_recsys = BaseLineRecSys('popularity')\n",
    "    try:\n",
    "        popularity_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except Exception as e:        \n",
    "        print('popularity function has error')\n",
    "        print(e)\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = popularity_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "testPopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Average Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testUserAverRecSys(validation_df=validation_df, BaseLineRecSys = BaseLineRecSys):\n",
    "    useraverage_recsys = BaseLineRecSys('average_user_rating')\n",
    "    try:\n",
    "        useraverage_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "    except:\n",
    "        print('useraverage function has error')\n",
    "        return\n",
    "    try:\n",
    "        predictionMatrix = useraverage_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated 0 users\n",
      "calculated 100 users\n",
      "calculated 200 users\n",
      "calculated 300 users\n",
      "calculated 400 users\n",
      "calculated 500 users\n",
      "calculated 600 users\n",
      "calculated 700 users\n",
      "calculated 800 users\n",
      "calculated 900 users\n"
     ]
    }
   ],
   "source": [
    "testPopularityRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similary Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testEuclidean(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.euclidean(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testEuclidean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Similarity Function (test somethingelse function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testCustomizedSim(validation_df=validation_df, getMatrix=CrossValidation.getMatrix):\n",
    "    matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    try:\n",
    "        sim_matrix = SimBasedRecSys.somethingelse(matrix)\n",
    "        assert(sim_matrix.shape == (ROW_NUM, ROW_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(sim_matrix.shape,ROW_NUM,ROW_NUM)\n",
    "        assert(np.any(sim_matrix <= 1)),\\\n",
    "               \"Exist similarity value that is not less or equal to 1.\"\n",
    "    except Exception as e:\n",
    "        print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testCustomizedSim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-User Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testUUSimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('user','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please contact TA if you see this.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testUUSimBasedRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-Item Similarity Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testIISimBasedRecSys(validation_df=validation_df, dataPreprocessor=dataPreprocessor):\n",
    "    try:\n",
    "        user_cosine_recsys = SimBasedRecSys('item','cosine', dataPreprocessor)\n",
    "    except:\n",
    "        print(\"Framework error, please contact TA if you see this.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        user_cosine_recsys.predict_all(validation_df, ROW_NUM, COL_NUM)\n",
    "        predictionMatrix = user_cosine_recsys.getModel()\n",
    "        assert(predictionMatrix.shape == (ROW_NUM, COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape ({1},{2})\"\\\n",
    "        .format(predictionMatrix.shape,ROW_NUM, COL_NUM)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testIISimBasedRecSys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Refrences\n",
    "Collaborated with Kamil Yilaci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
